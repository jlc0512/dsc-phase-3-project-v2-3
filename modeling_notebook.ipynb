{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as SNS\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, \\\n",
    "                            plot_confusion_matrix, plot_roc_curve, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cleaned data file\n",
    "df = pd.read_csv('final_data.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our predictors and target\n",
    "X = df.drop('status_group', axis=1)\n",
    "y = df.status_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confirm that out training data set is 3x larger than the testing dataset\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a dummy model that always predicts the most frequent class. In this case, our dummy model will predict that all of the water wells are functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our dummy regressor object\n",
    "dummy = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on our training data\n",
    "dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the accuracy of our initial dummy model\n",
    "dummy.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dummy model accuracy of 54.6% reflects the distribution of our target. Thus, if we always predict that a water well is functional, we will achieve 54.6% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our sub pipelines for numeric and categorial data\n",
    "subpipe_num = Pipeline(steps=[('ss', StandardScaler())])\n",
    "subpipe_cat = Pipeline(steps=[('ohe', OneHotEncoder(sparse=False, \n",
    "                                                    handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include our sub pipelines in a column transformer to OHE our categorial variables and scale our numerical variables.\n",
    "CT = ColumnTransformer(transformers=[('subpipe_num', subpipe_num, [0,2,17]), \n",
    "                                     ('subpipe_cat', subpipe_cat, [1,3,4,5,6,7,8,9,10,11,12,13,14,15,16])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline for Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline(steps=[('CT', CT), \n",
    "                              ('logreg', LogisticRegression(random_state=42))])\n",
    "\n",
    "knn_pipe = Pipeline(steps=[('CT', CT), \n",
    "                              ('knn', KNeighborsClassifier())])\n",
    "\n",
    "dtc_pipe = Pipeline(steps=[('CT', CT), \n",
    "                              ('dtc', DecisionTreeClassifier(random_state=42))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit each pipeline to our training data\n",
    "logreg_pipe.fit(X_train, y_train)\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "dtc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initial accuracy scores for each our our simple classifier models\n",
    "logreg_score = logreg_pipe.score(X_train, y_train)\n",
    "knn_score = knn_pipe.score(X_train, y_train)\n",
    "dtc_score = dtc_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out initial accuracy scores\n",
    "print(f'Logistic Regression Accuracy: {round(logreg_score * 100, 2)}%')\n",
    "print(f'KNearestNeighbors Accuracy: {round(knn_score * 100, 2)}%')\n",
    "print(f'DecisionTree Accuracy: {round(dtc_score * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial numbers appear to be relatively good. We expect our decision tree classifier to be overfit given the high accuracy score. We will dive deeper into more complex models below to maximize our accuracy and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our random forest pipeline to incorporate column transformer\n",
    "rfc_pipe = Pipeline(steps=[('CT', CT),\n",
    "                          ('rfc', RandomForestClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our random forest classifier to the training data\n",
    "rfc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(estimator=rfc_pipe, X=X_train, y=y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that our cross validation scores were significantly lower than the accuracy score from our single random forest classifier, we can say that this model is overfit to the training data. We will perform a grid search in order to optimize the hyper parameters of this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our grid for the grid search parameters\n",
    "params = {'rfc__n_estimators': [50, 100, 150],\n",
    "          'rfc__min_samples_split': [2, 10, 50],\n",
    "          'rfc__max_depth': [5, 10, 15]}\n",
    "\n",
    "# set up GridSearchCV object\n",
    "grid_rfc = GridSearchCV(rfc_pipe, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our grid object for random forests to the training data\n",
    "grid_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our initial grid search, we attained an accuracy of 78.3% using a max_depth of 15, a min_samples_split of 2, and an n_estimators of 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_rfc.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our initial grid search results, we can infer that a larger max depth is needed to improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our grid for the grid search parameters\n",
    "params2 = {'rfc__n_estimators': [50, 100, 150],\n",
    "           'rfc__max_depth': [15, 25, 50]}\n",
    "\n",
    "# set up GridSearchCV object\n",
    "grid_rfc2 = GridSearchCV(rfc_pipe, param_grid=params2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our grid object with parameter updates for random forests to the training data\n",
    "grid_rfc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_rfc2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our second grid search, we attained an accuracy of 79.0% using a max_depth of 25 and an n_estimators of 150. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_rfc2.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our new grid search, we can see that a maximum depth greater than 15 but less than 50 is ideal. We will also try running the grid search with a higher number of trees in the random forest to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our grid for the grid search parameters\n",
    "params3 = {'rfc__n_estimators': [100, 150, 200],\n",
    "           'rfc__max_depth': [20, 25, 30]}\n",
    "\n",
    "# set up GridSearchCV object\n",
    "grid_rfc3 = GridSearchCV(rfc_pipe, param_grid=params3, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid object to our training data with updated grid params for n_estimators and max_depth\n",
    "grid_rfc3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our third grid search, we attained an accuracy of 79.3% using a max_depth of 20 and an n_estimators of 150. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_rfc3.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our grid for the grid search parameters\n",
    "params4 = {'rfc__n_estimators': [100, 150],\n",
    "           'rfc__max_depth': [18, 20, 22],\n",
    "           'rfc__max_features': ['auto', 'sqrt', 0.2]}\n",
    "\n",
    "# set up GridSearchCV object\n",
    "grid_rfc4 = GridSearchCV(rfc_pipe, param_grid=params4, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_rfc4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our fourth grid search, we attained an accuracy of 79.4% using a max_depth of 20, a max_features of 0.2, and an n_estimators of 150. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_rfc4.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we run an inital XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBClassifier\n",
    "XGB_pipe = Pipeline(steps=[('CT', CT), \n",
    "                              ('XGB', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and test sets\n",
    "training_preds = XGB_pipe.predict(X_train)\n",
    "\n",
    "# Accuracy of training and test sets\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "training_recall = recall_score(y_train, training_preds, average= None)\n",
    "\n",
    "print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "print (training_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our massive grid for the grid search parameters\n",
    "paramsXGB = {\n",
    "    'XGB__learning_rate': [0.1, 0.2],\n",
    "    'XGB__max_depth': range(3, 10, 2),\n",
    "    'XGB__min_child_weight': range(1, 8, 2),\n",
    "    'XGB__gamma': [0, .1, .2],\n",
    "    'XGB__subsample': [.5, .75, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_XGB = GridSearchCV(XGB_pipe, param_grid=paramsXGB, cv=5)\n",
    "\n",
    "#Fit grid search object to our training data to check the hyper parameters\n",
    "##Did not complete, took too long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_XGB.best_params_\n",
    "\n",
    "print('Grid Search found the following optimal parameters: ')\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_clf.predict(X_train)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "training_recall = recall_score(y_train, training_preds)\n",
    "\n",
    "print('')\n",
    "print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ran some recall scores, realizing we may need to adjust data due to \n",
    "#undersampling of function but needs repairs class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current breakdown of our percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3225/44271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16887/44271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24159/44271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
